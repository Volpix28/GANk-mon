{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_fid import fid_score\n",
    "\n",
    "# dataset_path = 'dataset/training/base'\n",
    "# generations_path = 'outputs/_saved_examples_50_epochs_base/step5'\n",
    "# batch_size = 32\n",
    "# device = 'cuda'\n",
    "# dims = 64\n",
    "# # 64: first max pooling features\n",
    "# # 192: second max pooling features\n",
    "# # 768: pre-aux classifier features\n",
    "# # 2048: final average pooling features (this is the default)\n",
    "\n",
    "# print(fid_score)\n",
    "# fid_value = fid_score.calculate_fid_given_paths(\n",
    "#         [dataset_path, generations_path], batch_size, device, dims,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quality_metrics import nn_metric, ssim_metric, waterstein_distance_metric, fid_metric\n",
    "from utils.example_generator import generate_examples\n",
    "from progressive_gan import Generator, Discriminator, train_fn, set_seeds\n",
    "import os\n",
    "import torch\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_datasets = {'2D_assets': './dataset/2D_assets/transformed/', \n",
    "                #  'bulbapedia': './dataset/bulbapedia/transformed/',\n",
    "                #  'all_assets_and_bulbapedia': './dataset/all_assets_and_bulbapedia/transformed/',\n",
    "                #  'all_assets': './dataset/all_assets/transformed/'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#256 models have been ignored for fair comparison\n",
    "generators_paths = ['./outputs/6_test_6_bulbapedia_265x265/generator_128.pth',\n",
    "                    # '/outputs/23_first_try_bulbapedia_23_bulbapedia_256x256_e50/generator_128.pth',\n",
    "                    # './outputs/29_giga_dataset_29_all_assets_and_bulbapedia_256x256_e50/generator_64_40.pth',\n",
    "                    # './outputs/31_fine_tune_23_with_giga_dataset_31_all_assets_and_bulbapedia_128x128_e100/generator_128_150.pth',\n",
    "                    # './outputs/31_fine_tune_23_with_giga_dataset_31_all_assets_and_bulbapedia_128x128_e100/generator_128_130.pth',\n",
    "                    # './outputs/33_fine_tune_23_with_clean_dataset_33_2D_assets_128x128_e100/generator_128_150.pth',\n",
    "                    # './outputs/1_test_1_2D_assets_128x128_e50/generator_128.pth',\n",
    "                    # './outputs/36_fine_tune_1_with_clean_dataset_36_2D_assets_128x128_e100'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['generator', 'dataset', 'nn', 'ssim', 'waterstein', 'fid', 'path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'evaluation'\n",
    "z_dim = 256\n",
    "in_channels = 256\n",
    "img_channels = 3\n",
    "device = 'cpu'\n",
    "amount_examples = 100\n",
    "\n",
    "for path in generators_paths:\n",
    "    gen = Generator(\n",
    "        256, 256, img_channels=img_channels).to(device)\n",
    "    gen.load_state_dict(torch.load(path))\n",
    "    generator_size = int(path.split('/')[-1].split('_')[1].split('.')[0])\n",
    "    step = int(log2(generator_size / 4))\n",
    "    generator_name = path.split('/')[-2]\n",
    "    generations_path = os.path.join(base_path, generator_name)\n",
    "    os.makedirs(generations_path, exist_ok=True)\n",
    "    generate_examples(gen, step, z_dim, device=device, path=generations_path, n=amount_examples)\n",
    "    generations_path = os.path.join(generations_path, f'step{step}')\n",
    "    for ds_name, ds_path in real_datasets.items():\n",
    "        # nn = nn_metric(ds_path, generations_path)\n",
    "        # ssim = ssim_metric(ds_path, generations_path)\n",
    "        waterstein = waterstein_distance_metric(ds_path, generations_path)\n",
    "        fid = fid_metric(ds_path, generations_path)\n",
    "        # df.loc[len(df)] = [generator_name, ds_name, nn, ssim, waterstein, fid, generations_path]\n",
    "        df.loc[len(df)] = [generator_name, ds_name, 0, 0, waterstein, fid, generations_path]\n",
    "    \n",
    "df.to_csv(os.path.join(base_path,'evaluation.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the FID score between two datasets, where images of each dataset are contained in an individual folder:\n",
    "\n",
    "`python -m pytorch_fid path/to/dataset1 path/to/dataset2`\n",
    "\n",
    "To run the evaluation on GPU, use the flag --device cuda:N, where N is the index of the GPU to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
